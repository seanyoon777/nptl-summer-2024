{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NeuralProcessor import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "t12_t12.2022.08.13_Data__NSP2_NSP Data_1_neuralProcess_Complete_bld(001).ns5 opened\n",
      "\n",
      "t12_t12.2022.08.13_Data__NSP2_NSP Data_1_neuralProcess_Complete_bld(001).ns5 closed\n",
      "\n",
      "t12_t12.2022.08.13_Data__NSP1_NSP Data_1_neuralProcess_Complete_bld(001)002.ns5 opened\n",
      "\n",
      "t12_t12.2022.08.13_Data__NSP1_NSP Data_1_neuralProcess_Complete_bld(001)002.ns5 closed\n"
     ]
    }
   ],
   "source": [
    "## filepaths and names, change this to your file location. \n",
    "data_path = '/Users/seonghyunyoon/Developer/nptl/lower_frequencies/Data'\n",
    "file_name_with_audio = 't12_t12.2022.08.13_Data__NSP1_NSP Data_1_neuralProcess_Complete_bld(001)002.ns5'\n",
    "file_name_without_audio = 't12_t12.2022.08.13_Data__NSP2_NSP Data_1_neuralProcess_Complete_bld(001).ns5'\n",
    "\n",
    "# The read_ns5_file function loads neural data from the ns5 file. \n",
    "# It can be used for both files with and without audio data. \n",
    "raw_neural_without_audio = read_ns5_file(f'{data_path}/{file_name_without_audio}', n_channels=128)\n",
    "raw_neural, audio = read_ns5_file(f'{data_path}/{file_name_with_audio}', n_channels=128, include_audio=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------------------\n",
    "# NeuralFeatureExtractor.py \n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# Functionalities for neural feature extraction, pre-processing and read/write utilities. Optimized \n",
    "# for speed and modularity.\n",
    "# Written by Sean Yoon [sean777@stanford.edu]. \n",
    "# Parts of code adapted from Maitreyee Wairagkar and Benyamin Meschede-Krasa. \n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# Created     : 2024-05-03\n",
    "# Last update : 2024-05-03\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "from Globals import *\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# Functions to read and write from ns5 files\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "def read_ns5_file(ns5_filename: str, n_channels: int, include_audio: bool=False, audio_channel: int=-1):\n",
    "    \"\"\"\n",
    "    This function reads raw neural data from a ns5 format file, including audio recordings.\n",
    "    Args:\n",
    "        ns5_filename  : filename of the ns5 file\n",
    "        n_channels    : number of channels to be included in analysis \n",
    "        include_audio : (optional) boolean indicating whether to include audio recording from file. \n",
    "                        defaults to False\n",
    "        audio_channel : optional, index of channel containing audio data. defaults to -1\n",
    "\n",
    "    Returns:\n",
    "        raw_neural : [samples x channels] shape array of raw voltage recordings in int16\n",
    "        audio      : (optional) vector of audio file with same length as raw_neural. also in int16\n",
    "    \"\"\"\n",
    "    \n",
    "    # open, read, and close ns5 file\n",
    "    nsx_file = NsxFile(ns5_filename)\n",
    "    all_dat = nsx_file.getdata('all', 0) # get all electrodes and start from 0s \n",
    "    nsx_file.close()\n",
    "    \n",
    "    # data is in last cell of 'data'. we only extract the first n_channel channels\n",
    "    raw_neural = all_dat['data'][-1][:n_channels,:] \n",
    "    \n",
    "    # extract audio signals from data\n",
    "    # convert default memmap format to numpy array for faster in-memory access in future processing\n",
    "    if include_audio:\n",
    "        audio = all_dat['data'][-1][audio_channel,:]\n",
    "        return np.asarray(raw_neural.T), np.asarray(audio)\n",
    "    else: \n",
    "        return np.asarray(raw_neural.T)\n",
    "\n",
    "\n",
    "def unscramble_chans(dat: np.ndarray, ch_to_elec: list=CH_TO_ELECTRODES): \n",
    "    \"\"\"\n",
    "    Unscrambles neural recording channels. The first and last 64 channels are for the arrays\n",
    "    implanted in the 6v inferior and superior area, respectively. Used for offline analysis.\n",
    "    Args:\n",
    "        dat        : [samples x channels] shape array of raw voltage recordings. \n",
    "        ch_to_elec : electrode number corresponding to each channel. default mapping in Globals.py\n",
    "\n",
    "    Returns:\n",
    "        unscrambled_dat : [samples x channels] shape array of unscrambled raw voltage recordings in int16. \n",
    "    \"\"\"\n",
    "    \n",
    "    unscrambled_dat = np.zeros(shape=dat.shape, dtype='int16')\n",
    "    for ch in range(len(ch_to_elec)): \n",
    "        unscrambled_dat[:,ch_to_elec[ch]] = dat[:,ch]\n",
    "    return unscrambled_dat\n",
    "    \n",
    "    \n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# NeuralProcessor class, used for denoising and feature extraction\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "class NeuralProcessor: \n",
    "    def __init__(self, params): \n",
    "        \"\"\"\n",
    "        Initializes the NeuralProcessor class to denoise and extract features from neural data. \n",
    "        Currently supports various data processing techniques including local field potential, \n",
    "        local motor potential, threshold crossing bin count, and spiking bandpower.\n",
    "        \n",
    "        Args:\n",
    "            params (dict) : Configuration parameters for feature extraction, with the following keys: \n",
    "                - processes (list)    : Preprocessing steps for denoising. Supported values include \n",
    "                  objects ButterworthFilter, ReReferenceFilter, DownSample.\n",
    "                - thresh_mults (list) : Threshold multipliers for deteftion, such as [-4.5, -4.0, \n",
    "                  -3.5]. Defaults to an empty list.\n",
    "                - thresh_method (str) : Method for calculating thresholds, either 'rms' or 'std'. \n",
    "                  Defaults to 'rms'.\n",
    "                - spike_pow_bands (list): Frequency bands in Hz for spiking bandpower calculations, \n",
    "                  e.g., [(100, 500), (400, 1000), (1000, 2500)]. Defaults to an empty list.\n",
    "                  \n",
    "                - bin_size (int)         : Bin size in ms for offline sliding window analysis.\n",
    "                - shift_size (int)       : Bin shift size in ms for offline sliding window analysis.\n",
    "        \n",
    "        Raises:\n",
    "            KeyError: If required parameters ('bin_size' or 'shift_size') are missing in `params`.\n",
    "\n",
    "        Example: \n",
    "            Initializes with custom parameters: \n",
    "            NP = NeuralProcessor({\n",
    "                \"processes\": [\n",
    "                    ButterworthFilter(\"bandpass\", [50, 200], ord=4, fs=30000), \n",
    "                    ReReferenceFilter(\"lrr\", max_seconds=30)\n",
    "                    ], \n",
    "                \"thresh_mults\": [-4.5, -4.0, -3.5], \n",
    "                \"thresh_method\": \"rms\", \n",
    "                \"spike_pow_bands\": [(100, 500), (400, 1000), (1000, 2500)], \n",
    "                \"bin_size\": 20, \n",
    "                \"shift_size\": 20, \n",
    "                \"fs\": 30000\n",
    "            })\n",
    "        \"\"\"\n",
    "        \n",
    "        self.processes        = params.get(\"processes\", [])\n",
    "        self.thresh_mults     = params.get(\"thresh_mults\", [])\n",
    "        self.thresh_method    = params.get(\"thresh_method\", \"rms\")\n",
    "        self.raw_thresholds    = params.get(\"thresh_values\", None)\n",
    "        self.spike_pow_bands  = params.get(\"spike_pow_bands\", [])\n",
    "        self.lmp_boxsizes     = params.get(\"lmp_boxsizes\", [])\n",
    "        self.bin_size         = params.get(\"bin_size\", 0)\n",
    "        self.shift_size       = params.get(\"shift_size\", 0)\n",
    "        \n",
    "        self.TCCExtractor = ThresholdCrossingExtractor(self.thresh_mults, self.bin_size, self.shift_size, self.thresh_method, self.raw_thresholds)\n",
    "        self.SBPExtractor = SpikePowExtractor(self.spike_pow_bands, self.bin_size, self.shift_size)\n",
    "        self._LMPExtractor = LMPExtractor(self.lmp_boxsizes) \n",
    "    \n",
    "    \n",
    "    def __call__(self, dat: np.ndarray, n_arrays: int, n_electrodes: int, fs: int, verbose: bool=False) -> dict: \n",
    "        \"\"\"\n",
    "        Denoises and extracts features for input data. \n",
    "        \n",
    "        Args:\n",
    "            dat          : [samples x channels] shape array of neural data\n",
    "            n_arrays     : number of arrays\n",
    "            n_electrodes : number of electrodes per array\n",
    "            fs           : sampling frequency of neural data\n",
    "            verbose      : prints progress after every denoising / feature extraction step\n",
    "        Returns:\n",
    "            out          : dictionary containing extracted features, each following [samples x channels]\n",
    "        \"\"\"\n",
    "        \n",
    "        lfp, fs_new = self.denoise(dat=dat, n_arrays=n_arrays, n_electrodes=n_electrodes, fs=fs, verbose=verbose) \n",
    "        out = self.extract_features(lfp, fs=fs_new, raw_threshold=self.raw_thresholds, verbose=verbose)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def denoise(self, dat: np.ndarray, n_arrays: int, n_electrodes: int, fs: int, verbose: bool=False) -> np.ndarray: \n",
    "        \"\"\"\n",
    "        Denoises input data. \n",
    "        \n",
    "        Args:\n",
    "            dat          : [samples x channels] shape array of neural data\n",
    "            n_arrays     : number of arrays\n",
    "            n_electrodes : number of electrodes per array\n",
    "            fs           : sampling frequency of neural data\n",
    "            verbose      : prints progress after every denoising / feature extraction step\n",
    "        Returns:\n",
    "            denoised     : [samples x channels] shape array of denoised data \n",
    "            fs_new       : new sampling frequency if modified during signal processing\n",
    "        \"\"\"\n",
    "        \n",
    "        denoised = dat.copy()\n",
    "        # create a copy of sampling frequency in case operations affecting sampling frequency (e.g.\n",
    "        # downsampling) are applied \n",
    "        fs_new = fs\n",
    "        \n",
    "        if verbose: \n",
    "            print(\"Denoising steps\")\n",
    "        \n",
    "        for i, process in enumerate(self.processes): \n",
    "            denoised = process(dat=denoised, n_arrays=n_arrays, n_electrodes=n_electrodes, fs=fs_new)\n",
    "\n",
    "            # update frequency stored in NeuralProcessor class if downsampling is applied\n",
    "            if isinstance(process, Downsampler): \n",
    "                fs_new = int(fs_new / process.ds_factor)\n",
    "            \n",
    "            if verbose: \n",
    "                print(f'[{i+1}/{len(self.processes)}]: {self._print_process(process)}')\n",
    "                \n",
    "        return denoised, fs_new\n",
    "        \n",
    "        \n",
    "    def extract_features(self, dat: np.ndarray, fs: int, raw_threshold=None, verbose: bool=False) -> dict: \n",
    "        \"\"\"\n",
    "        Extracts features from input data. \n",
    "        \n",
    "        Args:\n",
    "            dat          : [samples x channels] shape array of neural data\n",
    "            fs           : sampling frequency of neural data\n",
    "        Returns:\n",
    "            out          : dictionary containing extracted features, each following [samples x channels]\n",
    "        \"\"\"\n",
    "        \n",
    "        # internal logic for numbering each feature extraction step – it's good to have this for debugging purposes\n",
    "        features_num = np.sum([True, \n",
    "                               len(self.TCCExtractor.multipliers) > 0, \n",
    "                               len(self.SBPExtractor.freq_bands) > 0, \n",
    "                               len(self._LMPExtractor.boxsizes) > 0])\n",
    "        i = 1\n",
    "        out = {\"lfp\": dat}\n",
    "        \n",
    "        if verbose: \n",
    "            print(\"Feature extraction steps\")\n",
    "            print(f'[{i}/{features_num}] Local field potentials extracted')\n",
    "            i += 1\n",
    "        \n",
    "        if len(self.TCCExtractor.multipliers) > 0: \n",
    "            out.update(self.TCCExtractor(dat, fs=fs))\n",
    "            if verbose: \n",
    "                print(f'[{i}/{features_num}] Threshold crossing counts extracted for multipliers {self.TCCExtractor.multipliers}')\n",
    "                i += 1\n",
    "        \n",
    "        if len(self.SBPExtractor.freq_bands) > 0: \n",
    "            out.update(self.SBPExtractor(dat, fs=fs))\n",
    "            if verbose: \n",
    "                print(f'[{i}/{features_num}] Spiking bancpower extracted for frequency bands {self.SBPExtractor.freq_bands}Hz')\n",
    "                i += 1\n",
    "            \n",
    "        if len(self._LMPExtractor.boxsizes) > 0: \n",
    "            out.update(self._LMPExtractor(dat, fs=fs))\n",
    "            if verbose: \n",
    "                print(f'[{i}/{features_num}] Local motor potentials extracted for box sizes {self._LMPExtractor.boxsizes}ms')\n",
    "                i += 1\n",
    "            \n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def append_processes(self, process: Any) -> None: \n",
    "        \"\"\"Appends denoising step\"\"\"\n",
    "        self.processes.append(process)\n",
    "    \n",
    "    \n",
    "    def remove_process(self, process: Any) -> None:\n",
    "        \"\"\"Removes denoising step\"\"\"\n",
    "        if process in self.processes: \n",
    "            self.processes.remove(process)\n",
    "\n",
    "    \n",
    "    def _print_process(self, process): \n",
    "        if isinstance(process, ReReferenceFilter): \n",
    "            if process.method.lower() == \"lrr\": \n",
    "                return f\"linear regression reference (LRR) filtered\"\n",
    "            elif process.method.lower() == \"car\": \n",
    "                return f\"common average reference (CAR) filtered\"\n",
    "        elif isinstance(process, Downsampler): \n",
    "            return f\"downsampled by factor of {process.ds_factor}\"\n",
    "        elif isinstance(process, ChevyshevFilter): \n",
    "            return f\"{process.filt_type} filtered (Chevyshev type I) for Wn={process.Wn}Hz\"\n",
    "        elif isinstance(process, ButterworthFilter): \n",
    "            return f\"{process.filt_type} filtered (Butterworth) for Wn={process.Wn}Hz\"\n",
    "        \n",
    "\n",
    "    def summary(table_width=70): \n",
    "        \"\"\"\n",
    "        Produces a summary of the NeuralProcessor\n",
    "        Args: \n",
    "        \n",
    "        \"\"\"\n",
    "        # logic for setting table width and checking whether parameters are valid\n",
    "\n",
    "\n",
    "    def summary(self, table_width=70): \n",
    "        \"\"\"\n",
    "        Produces a summary of the LMPExtractor class object\n",
    "        Args:\n",
    "            table_width : width of summary table. Defaults to 60 and minimum 50.\n",
    "        \"\"\"\n",
    "        # logic for setting table width and checking whether parameters are valid\n",
    "        if table_width < 50: \n",
    "            raise ValueError(\"Minimum width is 50\")\n",
    "        max_width = table_width - 2\n",
    "        \n",
    "        # prints table header\n",
    "        print(\"┌\" + \"─\" * max_width + \"┐\")\n",
    "        title = \"Neural processor configuration\"\n",
    "        left = int(np.ceil((max_width - len(title)) / 2))\n",
    "        right = int(np.floor((max_width - len(title)) / 2))\n",
    "        print(\"│\" + \" \" * left + title + \" \" * right + \"│\")\n",
    "        print(\"├\" + \"=\" * max_width + \"┤\")\n",
    "        \n",
    "        # prints denoising table subheader\n",
    "        processes_title = \"Denoising steps:\"\n",
    "        print(\"| \" + processes_title + \" \" * (max_width - len(processes_title) - 1) + \"|\")\n",
    "        print(\"├\" + \"─\" * max_width + \"┤\")\n",
    "        for process in self.processes: \n",
    "            pass \n",
    "            #process.summary(table_width)\n",
    "        print(\"├\" + \"=\" * max_width + \"┤\")\n",
    "        \n",
    "        # prints feature extraction table subheader \n",
    "        feature_title = \"Output features:\"\n",
    "        print(\"| \" + feature_title + \" \" * (max_width - len(feature_title) - 1) + \"|\")\n",
    "        print(\"├\" + \"─\" * max_width + \"┤\")\n",
    "        if len(self.thresh_mults) > 0: \n",
    "            self.TCCExtractor.summary(table_width)\n",
    "        if len(self.lmp_boxsizes) > 0: \n",
    "            self._LMPExtractor.summary(table_width)\n",
    "            \n",
    "        print(\"└\" + \"─\" * max_width + \"┘\")\n",
    "        \n",
    "        # # handle potentially long text for boxcar filter sizes\n",
    "        # coltext = \"│ Boxcar filter size (ms) : \" + \" |\"\n",
    "        # space_width = table_width - len(coltext)\n",
    "        # mult_text = chunk_text(str(self.boxsizes), max_width=space_width)\n",
    "        \n",
    "        # # print frequency bands line by line\n",
    "        # for i, line in enumerate(mult_text): \n",
    "        #     if i == 0 : \n",
    "        #         print_line(f\"│ Boxcar filter size (ms) : {line}\", max_width)\n",
    "        #     else: \n",
    "        #         print_line(f\"│                           {line}\", max_width)\n",
    "\n",
    "        # print_line(f\"│ Signal sampling freq    : {self.fs} Hz \", max_width)\n",
    "        # \n",
    "        \n",
    "        \n",
    "        \n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# Optimized classes and functions for neural signal denoising, and preprocessing prior to feature \n",
    "# extraction. \n",
    "# Currently supported features & definitions: \n",
    "#     > Downsampling              : Downsampling\n",
    "#     > Frequency-based filtering : Bandpass, lowpass, and highpass filtering\n",
    "#     > Re-referencing            : Common average referencing (CAR) and linear regression \n",
    "#                                   referencing (LRR)\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "class Downsampler: \n",
    "    def __init__(self, ds_factor: float): \n",
    "        \"\"\"\n",
    "        Initalizes Downsampler class for downsampling signal. Assumes input data to be already \n",
    "        bandpass filtered. \n",
    "\n",
    "        Args:\n",
    "            ds_factor : downsampling factor\n",
    "        \"\"\"\n",
    "        self.ds_factor = ds_factor\n",
    "    \n",
    "    \n",
    "    def __call__(self, dat: np.ndarray, **kwargs): \n",
    "        \"\"\"\n",
    "        Downsamples input neural data. Assumes input data to be already filtered.\n",
    "        \n",
    "        Args: \n",
    "            dat : [samples x channels] shape array of neural data\n",
    "        \"\"\"\n",
    "        return dat[::self.ds_factor]\n",
    "\n",
    "\n",
    "class ChevyshevFilter: \n",
    "    def __init__(self, filt_type, Wn, rp, ord, fs, non_causal=True, t_delay=0): \n",
    "        # save in case frequency of the signal changes during processing before filter applied\n",
    "        self.filt_type = filt_type\n",
    "        self.rp = rp\n",
    "        self.Wn = Wn\n",
    "        self.ord = ord\n",
    "        self.fs = fs\n",
    "        self.non_causal = non_causal\n",
    "        self.t_delay = t_delay\n",
    "        \n",
    "        # check valid filter type\n",
    "        if filt_type not in ['bandpass', 'lowpass', 'highpass']:\n",
    "            raise ValueError(\"Unsupported filtering method\")\n",
    "        \n",
    "        # build filter and obtain parameters\n",
    "        self.params = signal.cheby1(N=ord, Wn=Wn, rp=rp, btype=filt_type, output='sos', fs=fs)\n",
    "        \n",
    "        \n",
    "    def __call__(self, dat, fs, **kwargs): \n",
    "        \"\"\"\n",
    "        Filters signal using cascaded second-order sections.\n",
    "\n",
    "        Args:\n",
    "            dat : [samples x channels] shape array of neural data\n",
    "            fs  : sampling frequency of neural data\n",
    "        Returns:\n",
    "            filtered : [samples x channels] shape array of filtered data\n",
    "        \"\"\"\n",
    "        # if the class is called by calling a NeuralProcessor object, the processes of the NeuralProcessor\n",
    "        # could've had changed the sampling frequency. We update the sampling frequency correspondingly. \n",
    "        if fs != self.fs: \n",
    "            self.params = signal.cheby1(N=self.ord, Wn=self.Wn, rp=self.rp, btype=self.filt_type, output='sos', fs=fs)\n",
    "        \n",
    "        # return filtered signal depending on causal or non-causal filtering\n",
    "        if self.non_causal: \n",
    "            filtered = signal.sosfiltfilt(self.params, dat, axis=0)\n",
    "            if self.t_delay != 0: \n",
    "                n_samples_delay = int(self.t_delay * fs / 1000)\n",
    "                filtered = np.roll(filtered, -n_samples_delay)\n",
    "            return filtered\n",
    "        return signal.sosfilt(self.params, dat, axis=0)\n",
    "    \n",
    "    \n",
    "class ButterworthFilter:\n",
    "    def __init__(self, filt_type, Wn, ord, fs, non_causal=True, t_delay=0): \n",
    "        \"\"\"\n",
    "        Initializes ButterworthFilter class for frequency-based filtering neural data. Currently \n",
    "        supports highpass, bandpass, and lowpass filtering. Uses a digital butterworth IIR filter \n",
    "        and its second-order sections representation for computation. \n",
    "        \n",
    "        Args:\n",
    "            filt_type  : The type of filter. One of {'bandpass', 'lowpass', 'highpass'}\n",
    "            Wn         : the critical frequency or frequencies. For lowpass and highpass filters, \n",
    "                         Wn is a scalar; for bandpass and bandstop filters, Wn is a length-2 sequence.\n",
    "            ord        : order of the butterworth filter. \n",
    "            fs         : sampling frequency of neural data. \n",
    "            non_causal : non causal (zero-phase) filtering. Defaults to true. \n",
    "            t_delay    : time delay to simulate a non-causal system\n",
    "\n",
    "        Raises:\n",
    "            ValueError: _description_\n",
    "        \"\"\"\n",
    "        # save in case frequency of the signal changes during processing before bandpass applied\n",
    "        self.filt_type = filt_type\n",
    "        self.Wn = Wn\n",
    "        self.ord = ord\n",
    "        self.fs = fs\n",
    "        self.non_causal = non_causal\n",
    "        self.t_delay = t_delay\n",
    "        \n",
    "        # check valid filter type\n",
    "        if filt_type not in ['bandpass', 'lowpass', 'highpass']:\n",
    "            raise ValueError(\"Unsupported filtering method\")\n",
    "        \n",
    "        # build filter and obtain parameters\n",
    "        self.params = signal.butter(N=ord, Wn=Wn, btype=filt_type, output='sos', fs=fs)\n",
    "\n",
    "    \n",
    "    # @staticmethod\n",
    "    # @nb.jit(nopython=True)\n",
    "    # def _delay(dat, n_samples_delay): \n",
    " \n",
    " ##TODO: def _delay(): \n",
    "        \n",
    "        \n",
    "    def __call__(self, dat, fs=0, **kwargs): \n",
    "        \"\"\"\n",
    "        Filters signal using cascaded second-order sections.\n",
    "\n",
    "        Args:\n",
    "            dat : [samples x channels] shape array of neural data\n",
    "            fs  : sampling frequency of neural data\n",
    "        Returns:\n",
    "            filtered : [samples x channels] shape array of filtered data\n",
    "        \"\"\"\n",
    "        # if the class is called by calling a NeuralProcessor object, the processes of the NeuralProcessor\n",
    "        # could've had changed the sampling frequency. We update the sampling frequency correspondingly. \n",
    "        if fs != self.fs and fs > 0: \n",
    "            self.params = signal.butter(N=self.ord, Wn=self.Wn, btype=self.filt_type, output='sos', fs=fs)\n",
    "        \n",
    "        # return filtered signal depending on causal or non-causal filtering\n",
    "        if self.non_causal: \n",
    "            filtered = signal.sosfiltfilt(self.params, dat, axis=0)\n",
    "            if self.t_delay != 0: \n",
    "                n_samples_delay = int(self.t_delay * fs / 1000)\n",
    "                filtered = np.roll(filtered, -n_samples_delay)\n",
    "            return filtered\n",
    "        return signal.sosfilt(self.params, dat, axis=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "class ReReferenceFilter: \n",
    "    def __init__(self, method: str, max_seconds: int=0, ref_dat: np.ndarray=None, ref_mat: np.ndarray=None): \n",
    "        \"\"\"\n",
    "        Initalizes the class ReReferenceFilter, a filter for performing re-referencing to eliminate \n",
    "        any noise or other common artifacts across neural channels. This class currently supports \n",
    "        common average referencing (CAR) or linear regression referencing (LRR) for each array. \n",
    "        \n",
    "        LRR is recommended since unlike CAR, it does not assume equal noise across all channels in \n",
    "        an array. For more information, see Young et al (2018): \n",
    "        https://iopscience.iop.org/article/10.1088/1741-2552/aa9ee8/pdf\n",
    "        \n",
    "        Args:\n",
    "            method      : re-referencing method, either 'car' or 'lrr' \n",
    "            max_seconds : Only for LRR. Length of data for calculating LRR coefficients. \n",
    "                          Uses entire data block by default if not specified. \n",
    "            ref_dat     : Optional, specific neural data of shape [samples x channels] for computing LRR weights. \n",
    "                          Uses input data to ReReferenceFilter if not specified. \n",
    "            ref_mat     : Optional, pre-computed LRR weights of shape [channels x channels]. \n",
    "        \"\"\"\n",
    "        # check that method is valid \n",
    "        method = method.lower()\n",
    "        if method not in ['car', 'lrr']:\n",
    "            raise ValueError(\"Unsupported re-referencing method\")\n",
    "        self.method = method \n",
    "        \n",
    "        # set other paramters\n",
    "        self.max_seconds = max_seconds\n",
    "        self.ref_dat     = ref_dat\n",
    "        self.ref_mat     = ref_mat\n",
    "        \n",
    "        # handle edge cases where ref_mat and ref_dat are both specified\n",
    "        if self.ref_mat is not None and self.ref_dat is not None: \n",
    "            print('Warning: Data for calculating coefficients specified in addition to pre-calculated coefficients. ')\n",
    "            print('         Neural data will be ignored. To avoid this, reinitialize with only ref_dat or ref_mat.')\n",
    "            \n",
    "    \n",
    "    def _car(self, dat: np.ndarray, n_arrays: int, n_electrodes: int, **kwargs) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Applies common average referencing (CAR) to neural data. \n",
    "        Args:\n",
    "            dat          : [samples x channels] shape array of neural data\n",
    "            n_arrays     : number of arrays\n",
    "            n_electrodes : number of electrodes per array\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: _description_\n",
    "        \"\"\"\n",
    "        dat      = dat.astype('float32')\n",
    "        denoised = np.zeros(shape=dat.shape, dtype='float32')\n",
    "        \n",
    "        if self.ref_mat is None: \n",
    "            if self.ref_dat is None: \n",
    "                ref_mat = self.get_weights(dat, n_arrays, n_electrodes)\n",
    "            else: \n",
    "                ref_mat = self.get_weights(self.ref_dat, n_arrays, n_electrodes)\n",
    "        else: \n",
    "            ref_mat = self.ref_mat \n",
    "            \n",
    "        # apply car to each array\n",
    "        for array in range(n_arrays):\n",
    "            start = n_electrodes * array \n",
    "            end   = n_electrodes * (array + 1)\n",
    "            dat_array = dat[:,start:end]\n",
    "            denoised[:,start:end] = self._car_denoise(dat_array, ref_mat[array])\n",
    "        \n",
    "        return denoised\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    @nb.jit(nopython=True)\n",
    "    def _get_car_weights(dat_array): \n",
    "        '''\n",
    "        Gets CAR weights from single array neural data \n",
    "        '''\n",
    "        dat_array    = np.ascontiguousarray(dat_array)\n",
    "        n_samples    = dat_array.shape[0]\n",
    "        common_noise = np.zeros(shape=(n_samples, 1), dtype='float32')\n",
    "        # for each timestamp, calculate reference (average of all channels)\n",
    "        for t in range(n_samples): \n",
    "            common_noise[t] = np.mean(dat_array[t,:])\n",
    "        return common_noise\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    @nb.jit(nopython=True)\n",
    "    def _car_denoise(dat_array, common_noise): \n",
    "        '''\n",
    "        CAR for single array neural data. \n",
    "        '''\n",
    "        dat_array    = np.ascontiguousarray(dat_array)\n",
    "        common_noise = np.ascontiguousarray(common_noise)\n",
    "        return dat_array - common_noise\n",
    "    \n",
    "    \n",
    "    def set_weights_as(self, ref_mat): \n",
    "        self.ref_mat = ref_mat\n",
    "        \n",
    "    \n",
    "    def set_weights_with(self, dat: np.ndarray, n_array: int, n_electrodes: int, fs: int): \n",
    "        self.ref_dat = dat\n",
    "        self.ref_mat = self.get_weights(dat, n_array, n_electrodes, fs)\n",
    "\n",
    "        \n",
    "    def reset_weights(self): \n",
    "        self.ref_mat = None\n",
    "    \n",
    "    \n",
    "    def get_weights(self, dat: np.ndarray, n_arrays: int, n_electrodes: int, fs: int=None): \n",
    "        '''\n",
    "        Returns: \n",
    "            weights : [arrays x samples x 1] for CAR, [arrays x channels x channels] for LRR\n",
    "        '''\n",
    "        n_samples, n_channels = dat.shape\n",
    "        \n",
    "        if self.method == \"car\": \n",
    "            weights = np.zeros(shape=(n_arrays, n_samples, 1), dtype='float32')\n",
    "        elif self.method == \"lrr\": \n",
    "            weights = np.zeros(shape=(n_arrays, n_channels, n_channels), dtype='float32')\n",
    "            \n",
    "        for array in range(n_arrays): \n",
    "            start = n_electrodes * array \n",
    "            end   = n_electrodes * (array + 1)\n",
    "            dat_array = dat[:,start:end]\n",
    "            if self.method == \"car\": \n",
    "                weights[array] = self._get_car_weights(dat_array)\n",
    "            elif self.method == \"lrr\": \n",
    "                weights[array] = self._get_lrr_weights(dat_array, fs=fs, max_seconds=self.max_seconds)\n",
    "        \n",
    "        return weights\n",
    "            \n",
    "        \n",
    "    @staticmethod \n",
    "    @nb.jit(nopython=True) \n",
    "    def _get_lrr_weights(dat: np.ndarray, fs: int, max_seconds: int=0) -> np.ndarray: \n",
    "        \"\"\"\n",
    "        Calculates LRR weights for neural data from single array. \n",
    "        Args:\n",
    "            dat         : [samples x channels] shaped neural data from single array\n",
    "            max_seconds : maximum number of seconds (s) for LRR weight calculation\n",
    "            fs          : sampling frequency of neural data\n",
    "\n",
    "        Returns:\n",
    "            ref_mat : [channels x channels] LRR weights for single array\n",
    "        \"\"\"\n",
    "        n_samples, n_channels = dat.shape\n",
    "        dat     = np.ascontiguousarray(dat.astype('float32'))\n",
    "        ref_mat = np.zeros(shape=(n_channels, n_channels), dtype='float32')\n",
    "        \n",
    "        '''\n",
    "        Subsample data to use for LRR weight calculation.\n",
    "        Randomize the order of the data on the time axis to avoid biasing the LRR weights.\n",
    "        Only use up to max_seconds of data. If the data is less than max_seconds or if max_seconds\n",
    "        is not specified, use the entire data block. \n",
    "        Note that subsampling and randomization is only done for weight calculation. LRR is later \n",
    "        applied to all data.\n",
    "        '''\n",
    "        # if max_seconds is not specified, use the entire data block\n",
    "        if max_seconds == 0: \n",
    "            dat_sample = dat\n",
    "            max_idx = n_samples\n",
    "        # if specified, subsample data\n",
    "        else: \n",
    "            sample_len = max_seconds * fs\n",
    "            max_idx    = min(sample_len, n_samples)\n",
    "            rand_idx   = np.random.permutation(np.arange(n_samples))\n",
    "            use_idx    = rand_idx[0:max_idx]\n",
    "            dat_sample = dat[use_idx,:]\n",
    "            \n",
    "        for ch in range(n_channels): \n",
    "            '''\n",
    "            Here is where the LRR weights actually get calculated.\n",
    "            For each channel, we are calculating the weights of all other channels to be later \n",
    "            subtracted. \n",
    "            We do this by solving the equation:\n",
    "            Y = X*W\n",
    "            where Y is the data from the channel we are calculating weights for, X is the data from\n",
    "            all other channels, and W is the weight matrix.\n",
    "            Using least squares, we get the expression  \n",
    "            W = inv(X.T X) X.T Y\n",
    "            Repeat this for every channel. Resultant weight matrix is ref_mat, of size \n",
    "            [n_channels x n_channels].\n",
    "            '''\n",
    "            \n",
    "            # get a list of all channel indices excluding the current one \n",
    "            X = np.zeros(shape=(max_idx, n_channels - 1), dtype='float32')\n",
    "            X[:,ch:] = dat_sample[:,ch+1:]\n",
    "            X[:,:ch] = dat_sample[:,:ch]\n",
    "            X = np.ascontiguousarray(X)\n",
    "            y = np.ascontiguousarray(dat_sample[:,ch])\n",
    "            \n",
    "            # solve the optimized least squares to get weights for this channel\n",
    "            weights = lstsq_pseudoinverse(X, y)\n",
    "            \n",
    "            # Add the weights to the larger weight matrix of all channels in appropriate positions, \n",
    "            # leaving space for the current channel where the weight is zero\n",
    "            ref_mat[ch,:ch]   = weights[:ch] \n",
    "            ref_mat[ch,ch+1:] = weights[ch:] \n",
    "            \n",
    "        return ref_mat\n",
    "    \n",
    "    \n",
    "    @staticmethod \n",
    "    @nb.jit(nopython=True) \n",
    "    def _lrr_denoise(dat: np.ndarray, ref_mat: np.ndarray) -> np.ndarray: \n",
    "        \"\"\"\n",
    "        Denoises neural data from single array given LRR weights. \n",
    "\n",
    "        Args:\n",
    "            dat     : [samples x channels] shaped neural data from single array\n",
    "            ref_mat : [channels x channels] shaped LRR weights for single array\n",
    "\n",
    "        Returns:\n",
    "            denoised : [samples x channels] shaped denoised data from single array\n",
    "        \"\"\"\n",
    "        dat_array = np.ascontiguousarray(dat)\n",
    "        ref_mat = np.ascontiguousarray(ref_mat)\n",
    "        return dat_array - np.dot(dat_array, ref_mat)\n",
    "    \n",
    "    \n",
    "    def _lrr(self, dat: np.ndarray, n_arrays: int, n_electrodes: int, fs: int) -> np.ndarray: \n",
    "        \"\"\"\n",
    "        Denoises neural data using LRR. \n",
    "        Args:\n",
    "            dat          : [samples x channels] shape array of neural data\n",
    "            n_arrays     : total number of arrays\n",
    "            n_electrodes : number of electrodes per array\n",
    "            fs           : sampling frequency of neural data\n",
    "        Returns:\n",
    "            denoised : [samples x channels] shape of re-referenced data in float32 \n",
    "        \"\"\"\n",
    "        dat = dat.astype('float32')\n",
    "        denoised = np.zeros(shape=dat.shape, dtype='float32') \n",
    "\n",
    "        # retrieve reference matrix. If reference matrix do not exist but reference data is given, \n",
    "        # compute and save reference matrix. \n",
    "        if self.ref_mat is None: \n",
    "            if self.ref_dat is None: \n",
    "                ref_mat = self.get_weights(dat, n_arrays, n_electrodes, fs)\n",
    "            else: \n",
    "                ref_mat = self.get_weights(self.ref_dat, n_arrays, n_electrodes, fs)\n",
    "        else: \n",
    "            ref_mat = self.ref_mat\n",
    "            \n",
    "        # iterate over each array to denoise \n",
    "        for array in range(n_arrays): \n",
    "            start = n_electrodes * array \n",
    "            end   = n_electrodes * (array + 1)\n",
    "            dat_array = dat[:, start:end]\n",
    "            denoised[:, start:end] = self._lrr_denoise(dat_array, ref_mat=ref_mat[array])\n",
    "            \n",
    "        return denoised\n",
    "    \n",
    "       \n",
    "    def __call__(self, dat: np.ndarray, n_arrays: int, n_electrodes: int, fs: int, **kwargs) -> np.ndarray: \n",
    "        \"\"\"\n",
    "        Returns re-referenced signal using car or lrr. \n",
    "        Args:\n",
    "            dat          : [sample x channel] shape array of neural data\n",
    "            n_arrays     : total number of arrays\n",
    "            n_electrodes : number of electrodes per array\n",
    "        Returns:\n",
    "            denoised     : [sample x channel] shape array of re-referenced data in float32 \n",
    "        \"\"\"\n",
    "        # return different result based on method (car or lrr)\n",
    "        if self.method == 'car': \n",
    "            denoised = self._car(dat, n_arrays, n_electrodes, fs)\n",
    "        elif self.method == 'lrr': \n",
    "            denoised = self._lrr(dat, n_arrays, n_electrodes, fs)\n",
    "        return denoised\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# Optimized classes and functions for neural feature extraction. \n",
    "# Currently supported fetures & definitions: \n",
    "#     > Local field potential (LFP)   : Denoised data via the pipeline above is equivalent to LFP.\n",
    "#     > Local motor potential (LMP)   : Lower frequency components of local field potentials. Refer \n",
    "#                                       to Stavisky et al (2015) for more detail.\n",
    "#                                       https://iopscience.iop.org/article/10.1088/1741-2560/12/3/036009/pdf\n",
    "#     > Threshold crossing count/rate : Sum or average of threshold crossings for each time bin. \n",
    "#     > Spiking Bandpower (SBP)       : Power of signal for each time bin. \n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class LMPExtractor: \n",
    "    def __init__(self, boxsizes): \n",
    "        \"\"\"\n",
    "        Initializes the LMPExtractor class, used to extract local motor potentials from local field \n",
    "        potential data. Local motor potentials are obtained by boxcar filtering the LFP, which is \n",
    "        equivalent to a digital lowpass filter. For more detail, refer to Shenoy et al (2015): \n",
    "        https://iopscience.iop.org/article/10.1088/1741-2560/12/3/036009/pdf \n",
    "\n",
    "        Args:\n",
    "            boxsizes : list of boxsizes in ms\n",
    "            fs       : sampling frequency of neural data\n",
    "        \"\"\"\n",
    "        self.boxsizes = boxsizes \n",
    "        # if boxsizes is given as a single integer – this is for user convenience\n",
    "        if not isinstance(boxsizes, list): \n",
    "            self.boxsizes = [boxsizes]\n",
    "        self.fs = 0\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    @nb.njit(parallel=True)\n",
    "    def _compute_boxcar(dat, boxsize, fs): \n",
    "        \"\"\"\n",
    "        Optimized function for boxcar filtering. Parallelization is used for faster processing, \n",
    "        since np.convolve is quite slow. \n",
    "\n",
    "        Args:\n",
    "            dat     : [samples x channels] shape array of neural data\n",
    "            boxsize : boxcar filter size in ms\n",
    "            fs      : sampling frequency of neural data\n",
    "        Returns:\n",
    "            boxcar_dat : [samples x channels] shape array of boxcar filtered data \n",
    "        \"\"\"\n",
    "        # Initialize variables and boxcar filter\n",
    "        dat = dat.astype('float32')\n",
    "        boxsize_cnt = int(boxsize * fs / 1000) \n",
    "        window = np.ascontiguousarray(np.ones(boxsize_cnt, dtype='float32') / boxsize_cnt)\n",
    "        boxcar_dat = np.empty(shape=dat.shape, dtype='float32')\n",
    "        \n",
    "        # Iterate over channels and convolve with boxcar filter\n",
    "        for ch in nb.prange(dat.shape[1]): \n",
    "            ch_dat = np.ascontiguousarray(dat[:, ch])\n",
    "            boxcar_dat[:, ch] = np.convolve(ch_dat, window, mode='same')\n",
    "    \n",
    "        return boxcar_dat\n",
    "    \n",
    "    \n",
    "    def summary(self, table_width=60): \n",
    "        \"\"\"\n",
    "        Produces a summary of the LMPExtractor class object\n",
    "        Args:\n",
    "            table_width : width of summary table. Defaults to 60 and minimum 50.\n",
    "        \"\"\"\n",
    "        # logic for setting table width and checking whether parameters are valid\n",
    "        if table_width < 50: \n",
    "            raise ValueError(\"Minimum width is 50\")\n",
    "        max_width = table_width - 2\n",
    "        \n",
    "        # prints table header\n",
    "        print(\"┌\" + \"─\" * max_width + \"┐\")\n",
    "        title = \"Local motor potential extractor configuration\"\n",
    "        left = int(np.ceil((max_width - len(title)) / 2))\n",
    "        right = int(np.floor((max_width - len(title)) / 2))\n",
    "        print(\"│\" + \" \" * left + title + \" \" * right + \"│\")\n",
    "        print(\"├\" + \"─\" * max_width + \"┤\")\n",
    "        \n",
    "        # handle potentially long text for boxcar filter sizes\n",
    "        coltext = \"│ Boxcar filter size (ms) : \" + \" |\"\n",
    "        space_width = table_width - len(coltext)\n",
    "        mult_text = chunk_text(str(self.boxsizes), max_width=space_width)\n",
    "        \n",
    "        # print frequency bands line by line\n",
    "        for i, line in enumerate(mult_text): \n",
    "            if i == 0 : \n",
    "                print_line(f\"│ Boxcar filter size (ms) : {line}\", max_width)\n",
    "            else: \n",
    "                print_line(f\"│                           {line}\", max_width)\n",
    "\n",
    "        print_line(f\"│ Signal sampling freq    : {self.fs} Hz \", max_width)\n",
    "        print(\"└\" + \"─\" * max_width + \"┘\")\n",
    "    \n",
    "        \n",
    "    def __call__(self, dat, fs, **kwargs): \n",
    "        \"\"\"\n",
    "        Extracts local motor potentials from the input data based on specified configuration\n",
    "        parameters. \n",
    "        \n",
    "        Args:\n",
    "            dat : [samples x channels] shape array of neural data\n",
    "        Returns:\n",
    "            out : dict of boxcar filtered signal for each box size, each following \n",
    "                  [samples x channels] shape\n",
    "        \"\"\"\n",
    "        out = {} \n",
    "        self.fs = fs\n",
    "        # iterate over each boxsize and boxcar filter signal\n",
    "        for boxsize in self.boxsizes: \n",
    "            out[f\"lmp_{boxsize}\"] = self._compute_boxcar(dat, boxsize, self.fs)\n",
    "            \n",
    "        return out \n",
    "\n",
    "\n",
    "class ThresholdCrossingExtractor: \n",
    "    # TODO: implement threshold crossing rate too\n",
    "    def __init__(self, multipliers, bin_size, shift_size, method=\"rms\", raw_thresholds=None): \n",
    "        \"\"\"\n",
    "        Initializes the ThresholdCrossingExtractor class used for counting threshold crossing \n",
    "        instances in a specified bin. Used for offline sliding window analysis. \n",
    "        \n",
    "        Args:\n",
    "            multipliers : list of threshold multipliers. also accepts int or float (usually -4.5)\n",
    "            bin_size    : size of the bin in ms\n",
    "            shift_size  : size of the shift between bins in ms\n",
    "        \"\"\"\n",
    "        self.multipliers = multipliers\n",
    "        # contain input multiplier in list if it is single number – this is for user convenience\n",
    "        if not isinstance(multipliers, list): \n",
    "            self.multipliers = [multipliers]\n",
    "            \n",
    "        self.bin_size = bin_size \n",
    "        self.shift_size = shift_size\n",
    "        self.fs = 0\n",
    "        self.raw_thresholds = raw_thresholds\n",
    "        \n",
    "        # check whether method is valid\n",
    "        if method not in [\"rms\", \"std\"]: \n",
    "            raise ValueError(\"Unsupported thresholding method\")\n",
    "        self.method = method\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    @nb.jit(nopython=True)\n",
    "    def get_raw_threshold(dat, method=\"rms\"): \n",
    "        \"\"\"\n",
    "        Calculates the threshold for each channel before multipliying with specified factor. \n",
    "\n",
    "        Args:\n",
    "            dat    : [samples x channels] shape array of neural data\n",
    "            method : method used for calculating threshold values, one of {\"rms\" or \"std}. Defaults to \"rms\"\n",
    "        Returns:\n",
    "            raw_threshold : [channels] shape vector of threshold before multiplying\n",
    "        \"\"\"\n",
    "        dat = dat.astype('float32')\n",
    "        \n",
    "        # check whether method is valid\n",
    "        if method not in [\"rms\", \"std\"]:\n",
    "            raise ValueError(\"Unsupported thresholding method\")\n",
    "        \n",
    "        n_channels = dat.shape[1]\n",
    "        raw_threshold = np.zeros(n_channels, dtype='float32')\n",
    "        \n",
    "        # iterate over each channel to obtain threshold value\n",
    "        for ch in range(n_channels): \n",
    "            if method == \"rms\": \n",
    "                raw_threshold[ch] = np.sqrt(np.mean(np.square(dat[:,ch])))\n",
    "            elif method == \"std\": \n",
    "                raw_threshold[ch] = np.std(dat[:,ch])\n",
    "                \n",
    "        return raw_threshold\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    @nb.jit(nopython=True)\n",
    "    def count_threshold_crossings(dat, raw_threshold, mult, bin_size, shift_size, fs): \n",
    "        \"\"\"\n",
    "        Counts threshold crossings for given multiplier, bin size, and shift size. \n",
    "\n",
    "        Args:\n",
    "            dat           : [samples x channels] shape array of neural data \n",
    "            raw_threshold : [channels] shape vector of thresholds before multiplying. \n",
    "            mult          : threshold multiplier\n",
    "            bin_size      : bin size in ms\n",
    "            shift_size    : bin shift size in ms\n",
    "            fs            : sampling frequency of neural data \n",
    "\n",
    "        Returns:\n",
    "            crossings : [bins x channels] shape array of bin counts\n",
    "        \"\"\"\n",
    "        \n",
    "        # convert units to number of samples in bin, since bin_size is in millisecs\n",
    "        bin_cnt = int(bin_size * fs / 1000)\n",
    "        shift_cnt = int(shift_size * fs / 1000)\n",
    "        \n",
    "        # set data format and variables for numba\n",
    "        dat = dat.astype('float32')\n",
    "        n_bins = int(np.ceil(dat.shape[0] / shift_cnt))\n",
    "        n_channels = dat.shape[1]\n",
    "        crossings = np.zeros(shape=(n_bins, n_channels), dtype='float32')\n",
    "        if raw_threshold is not None: \n",
    "            raw_threshold = raw_threshold.astype('float32')\n",
    "        \n",
    "        # compare threshold values with neural recordings\n",
    "        threshold = raw_threshold * mult \n",
    "        crossings_total = dat <= threshold\n",
    "        \n",
    "        # iterate over each bin and count crossings\n",
    "        for bin_i, i in enumerate(range(0, dat.shape[0], shift_cnt)): \n",
    "            crossings_bin = crossings_total[i:i+bin_cnt] \n",
    "            for ch in range(n_channels): \n",
    "                crossings[bin_i, ch] = np.sum(crossings_bin[:,ch])\n",
    "        \n",
    "        return crossings \n",
    "    \n",
    "        \n",
    "    def __call__(self, dat, fs, **kwargs): # the wrapper function\n",
    "        \"\"\"\n",
    "        Counts threshold crossings for input neural data. \n",
    "\n",
    "        Args:\n",
    "            dat           : [samples x channels] shape array of neural data \n",
    "            raw_threshold : [channels] shape vector of thresholds before multiplying, if already\n",
    "                            calculated. included to avoid redundant calculations. \n",
    "\n",
    "        Returns:\n",
    "            out : dict of threshold crossing counts, each following [bins x channels] shape\n",
    "        \"\"\"\n",
    "        out = {} \n",
    "        \n",
    "        self.fs = fs\n",
    "        # compute raw threshold value to avoid redundant calculations\n",
    "        if self.raw_thresholds is None:\n",
    "            self.raw_thresholds = self.get_raw_threshold(dat, self.method)\n",
    "        \n",
    "        # for each multiplier, get the threshold crossing bin counts\n",
    "        for mult in self.multipliers: \n",
    "            out[f\"threshold_{mult}\"] = self.count_threshold_crossings(dat, self.raw_thresholds, mult, \n",
    "                                                                      self.bin_size, self.shift_size, self.fs)\n",
    "        \n",
    "        return out \n",
    "    \n",
    "    \n",
    "    def summary(self, table_width=60): \n",
    "        \"\"\"\n",
    "        Provides a summary of the SpikePowExtractor class object. \n",
    "        Args:\n",
    "            table_width : width of summary table. Defaults to 60 and minimum 50.\n",
    "        \"\"\"\n",
    "        # logic for setting table width and checking whether parameters are valid\n",
    "        if table_width < 50: \n",
    "            raise ValueError(\"Minimum width is 50\")\n",
    "        max_width = table_width - 2\n",
    "        \n",
    "        # prints table header\n",
    "        print(\"┌\" + \"─\" * max_width + \"┐\")\n",
    "        title = \"Threshold crossing counter configuration\"\n",
    "        left = int(np.ceil((max_width - len(title)) / 2))\n",
    "        right = int(np.floor((max_width - len(title)) / 2))\n",
    "        print(\"│\" + \" \" * left + title + \" \" * right + \"│\")\n",
    "        print(\"├\" + \"─\" * max_width + \"┤\")\n",
    "        \n",
    "        # Handle potentially long text for threshold multipliers\n",
    "        coltext = \"│ Threshold multipliers   : \" + \" |\"\n",
    "        space_width = table_width - len(coltext)\n",
    "        mult_text = chunk_text(str(self.multipliers), max_width=space_width)\n",
    "        \n",
    "        # print threshold multipliers line by line\n",
    "        for i, line in enumerate(mult_text): \n",
    "            if i == 0 : \n",
    "                print_line(f\"│ Threshold multipliers   : {line}\", max_width)\n",
    "            else: \n",
    "                print_line(f\"│                           {line}\", max_width)\n",
    "        \n",
    "        # print other parameters\n",
    "        print_line(f\"│ Signal sampling freq    : {self.fs} Hz \", max_width)\n",
    "        print_line(f\"│ Bin size                : {self.bin_size} ms\", max_width)\n",
    "        print_line(f\"│ Shift size              : {self.shift_size} ms\", max_width)\n",
    "        print(\"└\" + \"─\" * max_width + \"┘\")\n",
    "    \n",
    "\n",
    "class SpikePowExtractor: \n",
    "    def __init__(self, freq_bands, bin_size, shift_size, ord=4): \n",
    "        \"\"\"\n",
    "        Initializes the SpikePowExtractor class used for extracting spiking bandpower for a\n",
    "        specified frequency band. Used for offline sliding window analysis. \n",
    "        \n",
    "        Args:\n",
    "            freq_bands : list of frequency bands.\n",
    "            bin_size   : size of the bin in ms.\n",
    "            shift_size : size of the shift between bins in ms.\n",
    "            fs         : sampling frequency of neural data. \n",
    "            ord        : optional parameter for order of butterworth filter. defaults to 4.\n",
    "        \"\"\"\n",
    "        self.freq_bands = freq_bands \n",
    "        self.ord = ord\n",
    "        self.bin_size = bin_size \n",
    "        self.shift_size = shift_size \n",
    "        self.fs = 0\n",
    "        \n",
    "        # handle edge case for flexibility: input is a single frequency band\n",
    "        if not isinstance(freq_bands, list): \n",
    "            self.freq_bands = [freq_bands]\n",
    "    \n",
    "    \n",
    "    def add_band(self, band):\n",
    "        \"\"\"Adds new frequency band to extractor configuration\"\"\"\n",
    "        if band not in self.freq_bands: \n",
    "            self.freq_bands.append(band) \n",
    "        \n",
    "        \n",
    "    def remove_band(self, band): \n",
    "        \"\"\"Removes frequency band from extractor configuration\"\"\"\n",
    "        if band in self.freq_bands: \n",
    "            self.freq_bands.remove(band)\n",
    "        \n",
    "        \n",
    "    def _get_band_dat(self, dat, band, fs, ord=4): \n",
    "        \"\"\"Bandpass filters neural data for given frequency band\"\"\"\n",
    "        if self.ord != ord: \n",
    "            ord = self.ord\n",
    "        dat_band = ButterworthFilter(\"bandpass\", Wn=band, fs=self.fs, ord=ord)(dat, fs=fs)\n",
    "        return dat_band\n",
    "    \n",
    "    \n",
    "    @staticmethod \n",
    "    @nb.jit(nopython=True)\n",
    "    def _bin_bandpower(dat, bin_size, shift_size, fs): \n",
    "        \"\"\"\n",
    "        Calculates binned power for given signal. \n",
    "\n",
    "        Args:\n",
    "            dat        : [samples x channels] shape array of neural data \n",
    "            bin_size   : size of the bin in ms\n",
    "            shift_size : size of the shift between bins in ms\n",
    "            fs         : sampling frequency of neural data\n",
    "\n",
    "        Returns:\n",
    "            binned_pow : [bins x channels] shaped power of signal for each time bin\n",
    "        \"\"\"\n",
    "        # convert milliseconds to number of time samples, since input is in ms\n",
    "        bin_cnt = int(bin_size * fs / 1000) \n",
    "        shift_cnt = int(shift_size * fs / 1000)  \n",
    "        \n",
    "        # calculates the power of signal for every timestep\n",
    "        dat = dat.astype('float32')\n",
    "        dat_pow = np.square(dat)\n",
    "        \n",
    "        # initialize band power variable\n",
    "        n_bins = int(np.ceil(dat_pow.shape[0] / shift_cnt))\n",
    "        n_channels = dat_pow.shape[1]\n",
    "        binned_bandpow = np.zeros(shape=(n_bins, n_channels), dtype='float64')\n",
    "        \n",
    "        # iterate over each bin and channel to compute the bin average power\n",
    "        for bin_i, i in enumerate(range(0, dat_pow.shape[0], shift_cnt)): \n",
    "            dat_bin = dat_pow[i:i+bin_cnt]\n",
    "            for ch in range(n_channels): \n",
    "                binned_bandpow[bin_i, ch] = np.mean(dat_bin[:,ch])\n",
    "                \n",
    "        return binned_bandpow\n",
    "    \n",
    "    \n",
    "    def __call__(self, dat, fs): \n",
    "        \"\"\"\n",
    "        Calculates binned power for signal within given frequency band. \n",
    "\n",
    "        Args:\n",
    "            dat : [samples x channels] shape array of neural data \n",
    "            fs  : sampling frequency of neural data\n",
    "        Returns:\n",
    "            out : dictionary of spiking bandpower for each frequency band, each with shape \n",
    "                  [bins x channels]\n",
    "        \"\"\"\n",
    "        out = {} \n",
    "        self.fs = fs\n",
    "        \n",
    "        # iterate over each frequency band \n",
    "        for band in self.freq_bands: \n",
    "            # get bandpassed neural data for frequency band\n",
    "            if band == 'full': \n",
    "                band_dat = dat.copy() \n",
    "                name = \"bandpower_full\"\n",
    "            else: \n",
    "                band_dat = self._get_band_dat(dat, band=band, fs=fs)\n",
    "                name = f\"bandpower_{band[0]}_{band[1]}Hz\"\n",
    "                \n",
    "            # get bandpower for bandpassed neural data \n",
    "            binned_bandpow = self._bin_bandpower(band_dat, self.bin_size, self.shift_size, self.fs)\n",
    "            out[name] = binned_bandpow\n",
    "            \n",
    "        return out\n",
    "\n",
    "\n",
    "    def summary(self, table_width=60): \n",
    "        \"\"\"\n",
    "        Provides a summary of the SpikePowExtractor class object. \n",
    "        Args:\n",
    "            table_width : width of summary table. Defaults to 60 and minimum 50.\n",
    "        \"\"\"\n",
    "        # logic for setting table width and checking whether parameters are valid\n",
    "        if table_width < 50: \n",
    "            raise ValueError(\"Minimum width is 50\")\n",
    "        max_width = table_width - 2\n",
    "        \n",
    "        # prints table header\n",
    "        print(\"┌\" + \"─\" * max_width + \"┐\")\n",
    "        title = \"Spike bandpower extractor configuration\"\n",
    "        left = int(np.ceil((max_width - len(title)) / 2))\n",
    "        right = int(np.floor((max_width - len(title)) / 2))\n",
    "        print(\"│\" + \" \" * left + title + \" \" * right + \"│\")\n",
    "        print(\"├\" + \"─\" * max_width + \"┤\")\n",
    "        \n",
    "        # handle potentially long text for frequency bands\n",
    "        coltext = \"│ Frequency bands (Hz)    : \" + \" |\"\n",
    "        space_width = max_width - len(coltext) + 2\n",
    "        freq_band_text = chunk_text(str(self.freq_bands), max_width=space_width)\n",
    "        \n",
    "        # print frequency bands line by line\n",
    "        for i, line in enumerate(freq_band_text): \n",
    "            if i == 0 : \n",
    "                print_line(f\"│ Frequency bands (Hz)    : {line}\", max_width)\n",
    "            else: \n",
    "                print_line(f\"│                           {line}\", max_width)\n",
    "\n",
    "        print_line(f\"│ Signal sampling freq    : {self.fs} Hz \", max_width)\n",
    "        print_line(f\"│ Bandpass filter         : {self.ord}th order butterworth\", max_width)\n",
    "        \n",
    "        bin_samples = int(self.bin_size * self.fs / 1000)\n",
    "        print_line(f\"│ Bin size                : {self.bin_size} ms ({bin_samples} samples)\", max_width)\n",
    "        \n",
    "        shift_samples = int(self.shift_size * self.fs / 1000)\n",
    "        print_line(f\"│ Shift size              : {self.shift_size} ms ({shift_samples} samples)\", max_width)\n",
    "        print(\"└\" + \"─\" * max_width + \"┘\")\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# Helper functions for the classes\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "def print_line(text, max_width): \n",
    "    \"\"\"Calculates required amount of whitespace for max_width length text and fills in whitespace\"\"\"\n",
    "    print(f\"{text}\" + \" \" * (max_width - len(text) + 1) + \"│\")\n",
    "\n",
    "\n",
    "def chunk_text(text, max_width): \n",
    "    \"\"\"Chunks text into max_width length lines\"\"\"\n",
    "    return [text[i:i + max_width] for i in range(0, len(text), max_width)]\n",
    "\n",
    "\n",
    "@nb.jit(nopython=True) \n",
    "def lstsq_pseudoinverse(X, y):\n",
    "    \"\"\"optimized function for calculating the Moore-Penrose pseudoinverse, given by A+ = (AT A)-1 AT\"\"\"\n",
    "    W = np.linalg.solve(X.T.dot(X), X.T.dot(y)) \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "FS=30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_neural1 = raw_neural[600000:700000]\n",
    "raw_neural2 = raw_neural_without_audio[600000:700000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRRfilter = ReReferenceFilter(\"lrr\")\n",
    "LRRfilter.set_weights_with(raw_neural1, 1, 128, FS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "Diagnostic_processor = NeuralProcessor({\n",
    "    \"processes\": [\n",
    "        ChevyshevFilter(\"lowpass\", Wn=[int(FS * 0.2)], rp=0.05, ord=8, fs=FS, non_causal=True), \n",
    "        Downsampler(ds_factor=2),\n",
    "        ButterworthFilter(\"bandpass\", Wn=[250, 4900], ord=4, fs=FS, non_causal=True)\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denoising steps\n",
      "[1/3]: lowpass filtered (Chevyshev type I) for Wn=[6000]Hz\n",
      "[2/3]: downsampled by factor of 2\n",
      "[3/3]: bandpass filtered (Butterworth) for Wn=[250, 4900]Hz\n",
      "Feature extraction steps\n",
      "[1/1] Local field potentials extracted\n"
     ]
    }
   ],
   "source": [
    "diagnostic_neural = Diagnostic_processor(raw_neural1, 1, 128, FS, verbose=True)['lfp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = ThresholdCrossingExtractor([],0,0,\"std\").get_raw_threshold(diagnostic_neural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature_extractor = NeuralProcessor({\n",
    "    \"processes\": [\n",
    "        LRRfilter,\n",
    "        ChevyshevFilter(\"lowpass\", Wn=[int(FS * 0.2)], rp=0.05, ord=8, fs=FS, non_causal=True), \n",
    "        Downsampler(ds_factor=2),\n",
    "        ButterworthFilter(\"bandpass\", Wn=[250, 4900], ord=4, fs=FS, non_causal=True)\n",
    "    ], \n",
    "    \"thresh_mults\": [-3.5, -4.5], \n",
    "    \"thresh_values\": threshold, \n",
    "    \"spike_pow_bands\": ['full'], \n",
    "    \"bin_size\": 20, \n",
    "    \"shift_size\": 20\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denoising steps\n",
      "[1/4]: linear regression reference (LRR) filtered\n",
      "[2/4]: lowpass filtered (Chevyshev type I) for Wn=[6000]Hz\n",
      "[3/4]: downsampled by factor of 2\n",
      "[4/4]: bandpass filtered (Butterworth) for Wn=[250, 4900]Hz\n",
      "Feature extraction steps\n",
      "[1/3] Local field potentials extracted\n",
      "[2/3] Threshold crossing counts extracted for multipliers [-3.5, -4.5]\n",
      "[3/3] Spiking bancpower extracted for frequency bands ['full']Hz\n"
     ]
    }
   ],
   "source": [
    "out = Feature_extractor(raw_neural2, 1, 128, FS, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.608,  -3.399,   2.982, ...,   1.783,  -2.11 ,  -1.889],\n",
       "       [ 13.986, -52.133,  24.832, ...,  22.445,  -9.771,  45.651],\n",
       "       [-30.076, -60.727,  54.136, ...,  52.666, -10.315,  40.07 ],\n",
       "       ...,\n",
       "       [ 21.838,  22.346, -39.422, ..., -30.498,  37.619,  15.959],\n",
       "       [ 23.569,  16.374, -32.203, ..., -19.055,  11.505,  -3.195],\n",
       "       [ -1.404,   3.791,   4.979, ...,  -4.749,  -0.835,  -3.784]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['lfp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., 18.,  9., ..., 87.,  2., 44.],\n",
       "       [ 0.,  4., 20., ..., 65.,  8., 38.],\n",
       "       [ 0.,  8., 12., ..., 72.,  7., 38.],\n",
       "       ...,\n",
       "       [ 0.,  4., 22., ..., 69.,  8., 35.],\n",
       "       [ 0.,  6., 23., ..., 72.,  4., 35.],\n",
       "       [ 2.,  7.,  9., ..., 49.,  6., 20.]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['threshold_-3.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lfp': array([[  0.107,  -0.569,  -0.698, ...,  -1.338,  -4.073, -10.353],\n",
       "        [ -9.437, -23.985,   3.003, ..., -31.082,  43.573,  33.721],\n",
       "        [ -2.719, -36.178,   1.289, ..., -62.298,  11.153,  53.642],\n",
       "        ...,\n",
       "        [-39.88 , -26.555,  34.439, ..., -47.725, -36.824, -43.109],\n",
       "        [ -7.897, -33.401,  21.142, ..., -26.313, -11.926, -16.702],\n",
       "        [ -3.032,  -5.17 ,   0.5  , ...,   2.028,  -3.794,   0.531]]),\n",
       " 'threshold_-3.5': array([[ 0., 18.,  9., ..., 87.,  2., 44.],\n",
       "        [ 0.,  4., 20., ..., 65.,  8., 38.],\n",
       "        [ 0.,  8., 12., ..., 72.,  7., 38.],\n",
       "        ...,\n",
       "        [ 0.,  4., 22., ..., 69.,  8., 35.],\n",
       "        [ 0.,  6., 23., ..., 72.,  4., 35.],\n",
       "        [ 2.,  7.,  9., ..., 49.,  6., 20.]], dtype=float32),\n",
       " 'threshold_-4.5': array([[ 0.,  7.,  2., ..., 72.,  0., 21.],\n",
       "        [ 0.,  3., 10., ..., 51.,  0., 21.],\n",
       "        [ 0.,  0.,  6., ..., 60.,  4., 23.],\n",
       "        ...,\n",
       "        [ 0.,  3.,  9., ..., 46.,  4., 17.],\n",
       "        [ 0.,  3., 13., ..., 58.,  0., 20.],\n",
       "        [ 0.,  0.,  3., ..., 34.,  0., 10.]], dtype=float32),\n",
       " 'bandpower_full': array([[ 634.306,  946.149, 1133.184, ..., 2786.571,  811.862, 2101.156],\n",
       "        [ 741.819,  697.787, 1482.847, ..., 2317.205, 1011.027, 1932.336],\n",
       "        [ 594.398,  789.907, 1363.827, ..., 3188.327,  953.12 , 1726.792],\n",
       "        ...,\n",
       "        [ 403.57 ,  769.417, 1471.494, ..., 2719.52 ,  900.196, 1305.914],\n",
       "        [ 466.876,  673.424, 1446.661, ..., 2399.186,  918.574, 1372.687],\n",
       "        [ 547.974,  827.355,  957.098, ..., 2077.791,  811.241, 1153.181]])}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nptl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
