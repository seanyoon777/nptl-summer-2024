{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NeuralProcessor import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "t12_t12.2022.08.13_Data__NSP2_NSP Data_1_neuralProcess_Complete_bld(001).ns5 opened\n",
      "\n",
      "t12_t12.2022.08.13_Data__NSP2_NSP Data_1_neuralProcess_Complete_bld(001).ns5 closed\n",
      "\n",
      "t12_t12.2022.08.13_Data__NSP1_NSP Data_1_neuralProcess_Complete_bld(001)002.ns5 opened\n",
      "\n",
      "t12_t12.2022.08.13_Data__NSP1_NSP Data_1_neuralProcess_Complete_bld(001)002.ns5 closed\n"
     ]
    }
   ],
   "source": [
    "## filepaths and names, change this to your file location. \n",
    "data_path = '/Users/seonghyunyoon/Developer/nptl/lower_frequencies/Data'\n",
    "file_name_with_audio = 't12_t12.2022.08.13_Data__NSP1_NSP Data_1_neuralProcess_Complete_bld(001)002.ns5'\n",
    "file_name_without_audio = 't12_t12.2022.08.13_Data__NSP2_NSP Data_1_neuralProcess_Complete_bld(001).ns5'\n",
    "\n",
    "# The read_ns5_file function loads neural data from the ns5 file. \n",
    "# It can be used for both files with and without audio data. \n",
    "raw_neural_without_audio = read_ns5_file(f'{data_path}/{file_name_without_audio}', n_channels=128)\n",
    "raw_neural, audio = read_ns5_file(f'{data_path}/{file_name_with_audio}', n_channels=128, include_audio=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "FS=30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_neural1 = raw_neural[600000:700000]\n",
    "raw_neural2 = raw_neural[500000:600000]\n",
    "#raw_neural2 = raw_neural_without_audio[600000:700000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRRfilter = ReReferenceFilter(\"lrr\")\n",
    "LRRfilter.set_weights_with(raw_neural1, 1, 128, FS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Diagnostic_processor = NeuralProcessor({\n",
    "    \"processes\": [\n",
    "        ChevyshevFilter(\"lowpass\", Wn=[int(FS * 0.2)], rp=0.05, ord=8, fs=FS, non_causal=True), \n",
    "        Downsampler(ds_factor=2),\n",
    "        ButterworthFilter(\"bandpass\", Wn=[250, 4900], ord=4, fs=FS, non_causal=True)\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denoising steps\n",
      "[1/3]: lowpass filtered (Chevyshev type I) for Wn=[6000]Hz\n",
      "[2/3]: downsampled by factor of 2\n",
      "[3/3]: bandpass filtered (Butterworth) for Wn=[250, 4900]Hz\n",
      "Feature extraction steps\n",
      "[1/1] Local field potentials extracted\n"
     ]
    }
   ],
   "source": [
    "diagnostic_neural = Diagnostic_processor(raw_neural1, 1, 128, FS, verbose=True)['lfp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = ThresholdCrossingExtractor([],0,0,\"rms\").get_raw_threshold(diagnostic_neural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.244, 14.782, 13.591, 13.891, 23.238, 15.419, 25.579, 29.752,\n",
       "       16.871, 17.178, 32.436, 17.995, 26.896, 36.182, 42.015, 26.135,\n",
       "       48.356, 27.355, 15.762, 19.091, 26.639, 68.675, 31.811, 47.562,\n",
       "       34.768, 27.396, 16.243, 18.388, 15.23 , 14.796, 18.073, 13.772,\n",
       "       20.244, 27.659, 31.408, 20.512, 21.243, 18.572, 27.49 , 25.136,\n",
       "       33.206, 36.674, 21.931, 34.944, 41.026, 28.113, 29.121, 54.572,\n",
       "       50.377, 35.034, 21.071, 27.968, 35.156, 36.237, 42.841, 37.056,\n",
       "       23.943, 21.681, 29.661, 26.604, 17.218, 27.043, 21.564, 30.965,\n",
       "       21.086, 23.908, 21.629, 22.823, 23.471, 20.179, 32.199, 20.975,\n",
       "       30.62 , 23.927, 24.757, 34.311, 28.213, 33.913, 26.465, 33.834,\n",
       "       22.027, 18.991, 29.16 , 36.091, 30.32 , 31.324, 37.593, 46.405,\n",
       "       20.206, 19.78 , 20.925, 24.403, 33.337, 41.046, 26.936, 22.275,\n",
       "       28.774, 32.271, 30.395, 32.139, 21.502, 36.499, 36.887, 22.488,\n",
       "       31.373, 24.42 , 23.815, 38.803, 29.327, 24.154, 33.387, 13.97 ,\n",
       "       34.492, 17.486, 26.051, 20.318, 21.639, 20.054, 18.817, 24.846,\n",
       "       32.096, 18.552, 30.207, 16.726, 30.245, 10.105, 17.831, 12.939],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature_extractor = NeuralProcessor({\n",
    "    \"processes\": [\n",
    "        LRRfilter,\n",
    "        ChevyshevFilter(\"lowpass\", Wn=[int(FS * 0.2)], rp=0.05, ord=8, fs=FS, non_causal=True), \n",
    "        Downsampler(ds_factor=2),\n",
    "        ButterworthFilter(\"bandpass\", Wn=[250, 4900], ord=4, fs=FS, non_causal=True)\n",
    "    ], \n",
    "    \"thresh_mults\": [-3.5, -4.5], \n",
    "    \"thresh_values\": threshold, \n",
    "    \"spike_pow_bands\": ['full'], \n",
    "    \"bin_size\": 20, \n",
    "    \"shift_size\": 20\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denoising steps\n",
      "[1/4]: linear regression reference (LRR) filtered\n",
      "[2/4]: lowpass filtered (Chevyshev type I) for Wn=[6000]Hz\n",
      "[3/4]: downsampled by factor of 2\n",
      "[4/4]: bandpass filtered (Butterworth) for Wn=[250, 4900]Hz\n",
      "Feature extraction steps\n",
      "[1/3] Local field potentials extracted\n",
      "[2/3] Threshold crossing counts extracted for multipliers [-3.5, -4.5]\n",
      "[3/3] Spiking bancpower extracted for frequency bands ['full']Hz\n"
     ]
    }
   ],
   "source": [
    "out = Feature_extractor(raw_neural2, 1, 128, FS, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.913,   2.471,  -3.655, ...,   0.329,  -0.904,   1.26 ],\n",
       "       [ -0.29 ,  47.42 ,  12.283, ...,  -1.07 ,  23.287, -29.432],\n",
       "       [-22.928,  67.085,  11.862, ...,  -3.965,  24.653, -46.607],\n",
       "       ...,\n",
       "       [  5.601, -22.046,  23.649, ..., -15.674,   0.749,  11.694],\n",
       "       [  6.161, -13.859,   7.912, ...,  -0.724,   9.766,  -1.258],\n",
       "       [ -0.747,   3.306,  -6.709, ...,  -0.332,  -3.119,  -1.554]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['lfp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.,  0., 17., ...,  5.,  0.,  8.],\n",
       "       [ 7.,  1., 10., ...,  2.,  0.,  7.],\n",
       "       [ 3.,  0., 10., ...,  3.,  1.,  2.],\n",
       "       ...,\n",
       "       [10.,  0.,  2., ...,  2.,  0.,  0.],\n",
       "       [14.,  1., 11., ..., 10.,  1.,  3.],\n",
       "       [ 2.,  0.,  5., ...,  3.,  2.,  2.]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['threshold_-3.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lfp': array([[  0.107,  -0.569,  -0.698, ...,  -1.338,  -4.073, -10.353],\n",
       "        [ -9.437, -23.985,   3.003, ..., -31.082,  43.573,  33.721],\n",
       "        [ -2.719, -36.178,   1.289, ..., -62.298,  11.153,  53.642],\n",
       "        ...,\n",
       "        [-39.88 , -26.555,  34.439, ..., -47.725, -36.824, -43.109],\n",
       "        [ -7.897, -33.401,  21.142, ..., -26.313, -11.926, -16.702],\n",
       "        [ -3.032,  -5.17 ,   0.5  , ...,   2.028,  -3.794,   0.531]]),\n",
       " 'threshold_-3.5': array([[ 0., 18.,  9., ..., 87.,  2., 44.],\n",
       "        [ 0.,  4., 20., ..., 65.,  8., 38.],\n",
       "        [ 0.,  8., 12., ..., 72.,  7., 38.],\n",
       "        ...,\n",
       "        [ 0.,  4., 22., ..., 69.,  8., 35.],\n",
       "        [ 0.,  6., 23., ..., 72.,  4., 35.],\n",
       "        [ 2.,  7.,  9., ..., 49.,  6., 20.]], dtype=float32),\n",
       " 'threshold_-4.5': array([[ 0.,  7.,  2., ..., 72.,  0., 21.],\n",
       "        [ 0.,  3., 10., ..., 51.,  0., 21.],\n",
       "        [ 0.,  0.,  6., ..., 60.,  4., 23.],\n",
       "        ...,\n",
       "        [ 0.,  3.,  9., ..., 46.,  4., 17.],\n",
       "        [ 0.,  3., 13., ..., 58.,  0., 20.],\n",
       "        [ 0.,  0.,  3., ..., 34.,  0., 10.]], dtype=float32),\n",
       " 'bandpower_full': array([[ 634.306,  946.149, 1133.184, ..., 2786.571,  811.862, 2101.156],\n",
       "        [ 741.819,  697.787, 1482.847, ..., 2317.205, 1011.027, 1932.336],\n",
       "        [ 594.398,  789.907, 1363.827, ..., 3188.327,  953.12 , 1726.792],\n",
       "        ...,\n",
       "        [ 403.57 ,  769.417, 1471.494, ..., 2719.52 ,  900.196, 1305.914],\n",
       "        [ 466.876,  673.424, 1446.661, ..., 2399.186,  918.574, 1372.687],\n",
       "        [ 547.974,  827.355,  957.098, ..., 2077.791,  811.241, 1153.181]])}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nptl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
